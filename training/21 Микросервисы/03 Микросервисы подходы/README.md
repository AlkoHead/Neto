# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Ответ

| требование | реализация |
|------------|------------|
| облачная система | GitLab EE/CE в облаке (Yandex Cloud) или собственное развертывание (self-hosted) |
| система контроля версий Git | Встроенные репозитории GitLab |
| репозиторий на каждый сервис | Отдельные проекты в GitLab (1 сервис = 1 репозиторий) |
| Запуск сборки по событию | Триггеры на `push`, `merge request`, `tag` через `.gitlab-ci.yml` |
| Запуск по кнопке | Manual jobs с пользовательскими переменными в интерфейсе GitLab |
| Привязка настроек к сборке | Переменные (`variables`) на уровне проекта, группы, pipeline, job |
| Шаблоны конфигураций | `.gitlab-ci.yml` с `include` и `extends` для переиспользования |
| Безопасное хранение секретов | CI/CD Variables (masked, protected), HashiCorp Vault integration (в EE) |
| Несколько конфигураций из одного репозитория | Разные `stages` и `rules` в `.gitlab-ci.yml`, мульти‑джобы |
| Кастомные шаги при сборке | Любой shell-скрипт в `script`: или custom Docker image |
| Собственные Docker‑образы | Сборка через `docker build` в пайплайне, хранение в `Registry` |
| Развёртывание агентов на своих серверах | Установка GitLab Runner на локальных серверах (Linux/Windows) |
| Параллельный запуск сборок | Несколько Runner‑ов, настройка `concurrent` в `config.toml` |
| Параллельное тестирование | Параллельные джобы в stages (например, `test:unit`, `test:integration`) |

### Обоснование выбора GitLab CI/CD

1. Полностью закрывает все требования без необходимости интеграции множества инструментов
2. Предназначен для микросервисных архитектур с поддержкой множества репозиториев
3. Балансирует между простотой и мощностью — от простых YAML до enterprise-возможностей
4. Экономически эффективен — один инструмент вместо 3-4 разных
5. Имеет cloud-вариант (SaaS) с возможностью гибридной архитектуры (собственные раннеры)

В качестве альтернативы хотелось бы выделить `Jenkins`
- Минус: сложная настройка, требует администрирования.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Ответ


| Требование / Решение | ELK Stack | Loki (+ Grafana) | LPG Stack | Graylog |
|----------------------|-----------|------------------|-----------|---------|
| 1. Сбор логов со всех хостов в центральное хранилище | - Filebeat на всех узлах (DaemonSet в K8s)<br> - Поддержка: контейнеры, VM, bare metal<br> - Единая точка сбора в Elasticsearch<br> - Масштабируется на тысячи узлов | - Promtail на всех узлах (DaemonSet)<br> - Оптимизирован для K8s/контейнеров<br> - Центральный Loki кластер<br> - Сложнее для гибридных сред (VM+bare metal) | - Тот же Promtail<br> - Централизация в Loki<br> - Лучше всего для pure cloud-native<br> - Требует адаптации для legacy хостов | - Sidecar/Filebeat агенты<br> - Центральный Graylog сервер<br> - Поддержка разнородных сред<br> - Тяжелее для больших кластеров |
| 2. Минимальные требования к приложениям, сбор из stdout | - Приложения только пишут в stdout<br> - Filebeat читает Docker/containerd logs<br> - Автоматический парсинг JSON<br> - Нет изменений в коде приложений | - Приложения пишут в stdout<br> - Promtail читает логи контейнеров<br> - Поддержка Docker log driver plugin<br> - Прозрачно для приложений | - Идентично Loki<br> - Zero-instrumentation подход<br> - Работает с любым stdout/stderr<br> - Простая конфигурация | - Stdout через Docker driver, Или Filebeat для сбора<br> - Требует настройки input'ов<br> - Немного больше конфигурации |
| 3. Гарантированная доставка логов | - Filebeat → Kafka → Logstash<br> - Persistent queues в Filebeat<br> - Retry с backoff<br> - Подтверждение записи в ES<br> - Производственная надежность | - Promtail WAL (write-ahead log)<br> - Retry при сбоях Loki<br> - Нет промежуточного буфера<br> - Может терять логи при длительном сбое Loki<br> - Подходит для большинства случаев | - Тот же механизм что Loki<br> - Локальный буфер на диске<br> - Ограниченная емкость буфера<br> - Для критичных логов нужен Kafka | - Встроенные input buffers<br> - Можно добавить Kafka перед Graylog<br> - Журналирование в MongoDB<br> - Хорошая надежность, но сложная настройка HA |
| 4. Поиск и фильтрация по записям | - Elasticsearch Query DSL<br> -  Полнотекстовый поиск по всему контенту<br> - Булева логика, фразы, регулярки, Агрегации, статистика<br> - Самый мощный поиск на рынке | - LogQL (как PromQL для логов)<br> - Быстрый поиск по labels (metadata)<br> - Ограниченный поиск по содержимому<br> - Нет сложных текстовых анализов<br> - Хорошо для structured JSON логов | - Тот же LogQL<br> - Нет морфологического поиска<br> - Оптимизирован для метрик-подобных запросов | - Собственный язык запросов<br> -  Rule-based фильтрация<br> - Полевой поиск хороший<br> -  Автодополнение полей<br> - Уступает Elasticsearch в сложных сценариях |
| 5. UI с доступом для разработчиков | - Kibana: специализированный UI для логов<br> - Discover tab для поиска<br> - Dev Tools для прямых запросов<br> - Role-based доступ<br> - Плавная кривая обучения | - Grafana Explore: единый для логов+метрик<br> - Разработчики знают Grafana<br> - Autocomplete для LogQL<br> - Нет некоторых log-specific features<br> - Более общий интерфейс | - Графана тот же<br> - Преимущество: если уже используют для метрик<br> - Минус: не так сфокусирован на логах<br> - Split view для сравнения логов | - Специализированный Graylog Web UI<br> - Мощный, но менее популярен<br> - Разработчики незнакомы<br> - Больше для операторов/SRE<br> - Сворачиваемые панели поиска |
| 6. Ссылка на сохранённый поиск | - Kibana Saved Objects<br> - Прямая URL с параметрами поиска<br> - Share между пользователями<br> - Экспорт/импорт<br> - Встроенная система шаринга | - Grafana Dashboard с переменными<br> - Ссылка на dashboard с preset query<br> - Нет native saved searches отдельно<br> - Можно сохранить query в panel<br> - Менее удобно для чистого поиска | - Аналогично Loki+Grafana<br> - Short links в Grafana<br> - Query variables в URL<br> - Подходит если работа через dashboards<br> - Нет отдельных "saved search" объектов | - Saved searches в Graylog UI<br> - Shareable links с параметрами<br> - Dashboard widgets из поисков<br> - Удобные bookmark-и<br> - Хорошо для операционных команд |

### Матрица принятия решения

| Если у вас... | Выбирайте... | Почему |
|---------------|--------------|--------|
| Критически важна гарантия доставки (финансовые транзакции) | ELK + Kafka | Промышленная надежность, не потеряет ни одного лога |
| Уже есть Grafana для метрик | LPG Stack | Единый интерфейс, разработчики уже знают |
| Ограниченный бюджет (ресурсы/деньги) | LPG Stack | В 5-10 раз дешевле по хранилищу и ресурсам |
| Pure Kubernetes среда | Loki/LPG | Оптимизирован для K8s, label-based индексация |
| Гибридная среда (K8s + VM) | ELK или Graylog | Универсальные агенты для всех типов хостов |
| Маленькая команда DevOps | LPG Stack | Проще эксплуатация, один стек для всего |
| Enterprise требования, безопасность | ELK Stack	Field-level security, audit, compliance |
| Быстрый старт, time-to-market | LPG Stack | Быстрое развертывание, меньше конфигурации |

**Вывод**: Учитывая что у нас крупная организация, наш выбор будет **ELK**.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Ответ

В начестве решения возьмём `Prometheus & Alertmanager & Grafana`(GAP)

**GAP** - это не отдельный продукт, а связка трёх открытых инструментов, образующих полноценную систему мониторинга:

- Prometheus — сбор и хранение метрик;
- Alertmanager — обработка и маршрутизация оповещений;
- Grafana — визуализация и анализ.

(хотя алертов нет в задании, но они критичны на практике)

| Требование | Реализация в GAP |
|------------|------------------|
| Сбор метрик со всех хостов | Node Exporter + Prometheus service discovery |
| Метрики ресурсов хостов (CPU, RAM, HDD, Network) |Node Exporter: CPU, RAM, Disk, Network, load, temperature |
| Метрики сервисов (CPU, RAM, HDD, Network) | cAdvisor для контейнеров + application metrics<br>OpenTelemetry SDK |
| Специфичные метрики сервисов |  Prometheus client libraries (Go, Java, Python, Node.js) |
| Пользовательский интерфейс для запросов и агрегации |	Grafana Explore + Prometheus expression browser |
| Панели для отслеживания состояния | Grafana dashboards с templating, annotations, sharing |

`GAP` — оптимальный выбор для микросервисной архитектуры, потому что:

1. Закрывает все заявленные требования «из коробки».
2. Масштабируется от маленького стартапа до крупной платформы.
3. Имеет активное сообщество и обширную документацию.
4. Интегрируется с современными инфраструктурами (Kubernetes, облака, контейнеризация).

### Альтернативы и почему не они

| Решение | Минус |
|---------|-------|
| Datadog |  Высокая стоимость, vendor lock-in, избыточны для многих задач |
| Zabbix | Сложная настройка для микросервисов, push-модель менее гибкая, слабая поддержка Kubernetes |
| ELK (для метрик) | Elasticsearch не оптимален для временных рядов; Kibana уступает Grafana в визуализации метрик |
| InfluxDB + Telegraf + Chronograf | Работает, но экосистема мельче, меньше готовых дашбордов, Telegraf сложнее настраивать в K8s |

